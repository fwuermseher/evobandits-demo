{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e738b407",
   "metadata": {},
   "source": [
    "# Comparison with other libraries\n",
    "\n",
    "This notebooks extends 'evobandits_demo.ipynb' to compare the GMAB algorithm with popular alternatives.\n",
    "\n",
    "Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from evobandits import CategoricalParam, Study, GMAB\n",
    "from irace import irace, Experiment, ParameterSpace, Scenario, Ordinal\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from application_example import (\n",
    "    genetic_algorithm,\n",
    "    TSP_OPT_COST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1250e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "\n",
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams[\"font.serif\"] = [\n",
    "    \"Computer Modern Roman\",\n",
    "    \"Times New Roman\",\n",
    "    \"Times\",\n",
    "    \"DejaVu Serif\",\n",
    "]\n",
    "mpl.rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca1b7f",
   "metadata": {},
   "source": [
    "## 1. Presets for the Optimization\n",
    "\n",
    "Identical number of runs, budget and a seed for reproduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be906aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_RUNS = 50\n",
    "SIM_BUDGET = 1000\n",
    "EVAL_BUDGET = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa176c8",
   "metadata": {},
   "source": [
    "All variables are modeled as ordinal variables from the ranges below to ensure identical search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b23b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE_RANGE = [i for i in range(50, 251, 1)]\n",
    "ELITE_SPLIT_RANGE = [i * 0.01 for i in range(21)]\n",
    "TOURNAMENT_SPLIT_RANGE = [i * 0.01 for i in range(11)]\n",
    "CROSSOVER_RATE_RANGE = [i * 0.01 for i in range(101)]\n",
    "MUTATION_RATE_RANGE = [i * 0.01 for i in range(101)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483b6f8",
   "metadata": {},
   "source": [
    "Size of the Search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6dd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combinations = len(POP_SIZE_RANGE) * len(ELITE_SPLIT_RANGE) \\\n",
    "    * len(TOURNAMENT_SPLIT_RANGE) * len(CROSSOVER_RATE_RANGE) * len(MUTATION_RATE_RANGE)\n",
    "\n",
    "print(f\"Number of distinct solutions:\\t{total_combinations:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759b99c",
   "metadata": {},
   "source": [
    "The number of generations for the genetic algorithm is fixed to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATIONS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d6ac6",
   "metadata": {},
   "source": [
    "### Why fix the number of generations?\n",
    "\n",
    "This is done to ensure that result for different configurations actually differ - the genetic algorithm achieves good performance for (nearly) all configurations for higher number of generations, which means optimization is not really needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59327efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_configuration(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return {\n",
    "        \"pop_size\": int(rng.choice(POP_SIZE_RANGE)),\n",
    "        \"elite_split\": float(rng.choice(ELITE_SPLIT_RANGE)),\n",
    "        \"tournament_split\": float(rng.choice(TOURNAMENT_SPLIT_RANGE)),\n",
    "        \"crossover_rate\": float(rng.choice(CROSSOVER_RATE_RANGE)),\n",
    "        \"mutation_rate\": float(rng.choice(MUTATION_RATE_RANGE)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4080b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "n_configs = 10\n",
    "n_samples = 20 # per generation and config\n",
    "generations = [100, 200, 300, 400, 500]\n",
    "\n",
    "# Create a number of configurations to compare\n",
    "# Best result from 'evobandits_demo.ipynb' is used as reference configuration\n",
    "configurations = dict(\n",
    "    {\n",
    "        \"Reference\": {\n",
    "            \"pop_size\": 250,\n",
    "            \"elite_split\": 0.02,\n",
    "            \"tournament_split\": 0.09,\n",
    "            \"mutation_rate\": 0.87,\n",
    "            \"crossover_rate\": 0.06,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "for i in range(1, n_configs):\n",
    "    seed = rng.integers(0, 2 ** 32 - 1, dtype=int)\n",
    "    configurations.update({f\"Random_{i}\": randomize_configuration(seed)})\n",
    "\n",
    "# Collect samples for each generation and number of generations\n",
    "results = {\n",
    "    \"configurations\": configurations,\n",
    "    \"generations\": generations,\n",
    "}\n",
    "for name, config in configurations.items():\n",
    "    results[name] = {}\n",
    "\n",
    "    for gen in generations:\n",
    "        gen_results = []\n",
    "        for _ in tqdm(range(n_samples), desc=f\"{name} | Gen {gen}\"):\n",
    "            seed = rng.integers(0, 2**32 - 1, dtype=int)\n",
    "            cost, _ = genetic_algorithm(\n",
    "                generations=gen,\n",
    "                pop_size=250,\n",
    "                elite_split=0.10,\n",
    "                tournament_split=0.05,\n",
    "                crossover_rate=0.04,\n",
    "                mutation_rate=config[\"mutation_rate\"],\n",
    "                seed=seed,\n",
    "            )\n",
    "            gen_results.append(cost)\n",
    "        results[name][gen] = gen_results\n",
    "\n",
    "json.dump(results, open(Path(\"_data/03_comparison_generations_cnt.json\"), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07418a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "lines = []\n",
    "\n",
    "for name, config in configurations.items():\n",
    "    gen_results = results[name]\n",
    "    means = [np.mean(gen_results[gen]) for gen in generations]\n",
    "    stds = [np.std(gen_results[gen]) for gen in generations]\n",
    "\n",
    "    if name == \"Reference\":\n",
    "        # Highlight the reference config\n",
    "        plt.errorbar(\n",
    "            generations,\n",
    "            means,\n",
    "            yerr=stds,\n",
    "            label=\"Reference Configuration\",\n",
    "            capsize=4,\n",
    "            marker=\"o\",\n",
    "            color=\"tab:blue\",\n",
    "            linewidth=2.5,\n",
    "        )\n",
    "    else:\n",
    "        plt.plot(\n",
    "            generations,\n",
    "            means,\n",
    "            color=\"C7\",\n",
    "            linewidth=1.2,\n",
    "            alpha=0.6,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "# Proxy line as label for all randomized configurations\n",
    "proxy_line = mlines.Line2D([], [], label=\"Randomized Configurations\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "handles.append(proxy_line)\n",
    "labels.append(proxy_line.get_label())\n",
    "plt.legend(handles=handles, labels=labels)\n",
    "\n",
    "plt.xlabel(\"Number of Generations\")\n",
    "plt.ylabel(\"Total Distance\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"_plots/06_comparison_ga_generations.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a22dc",
   "metadata": {},
   "source": [
    "## 3. Optimization\n",
    "\n",
    "For each optimizer:\n",
    "- Model the genetic_algorithm as objective function\n",
    "- Model the search space\n",
    "- Configure the algorithm\n",
    "- Execute for preset, identical budget and runs\n",
    "- Collect the results and re-sample to evaluate the \"true\" value of the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ea42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_true_value(seed, ga_configuration):\n",
    "    evaluations = []\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(EVAL_BUDGET):\n",
    "        seed_eval = rng.integers(0, 2**32 - 1, dtype=int)\n",
    "        best_cost = genetic_algorithm(seed=seed_eval, generations=GENERATIONS, **ga_configuration)\n",
    "        evaluations.append(best_cost)\n",
    "    mean_evaluation = np.mean(evaluations)\n",
    "    return mean_evaluation, evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868c88b",
   "metadata": {},
   "source": [
    "### 2.1 EvoBandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136290de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(seed: int, **params: dict):\n",
    "    \"\"\"Seeded, single-objective function to simulate the GA.\"\"\"\n",
    "    best_cost, _ = genetic_algorithm(seed=seed, generations=GENERATIONS, **params)\n",
    "    return best_cost\n",
    "\n",
    "params = {\n",
    "    \"pop_size\": CategoricalParam(POP_SIZE_RANGE),\n",
    "    \"elite_split\": CategoricalParam(ELITE_SPLIT_RANGE), \n",
    "    \"tournament_split\": CategoricalParam(TOURNAMENT_SPLIT_RANGE),\n",
    "    \"mutation_rate\": CategoricalParam(MUTATION_RATE_RANGE), \n",
    "    \"crossover_rate\": CategoricalParam(CROSSOVER_RATE_RANGE), \n",
    "}\n",
    "\n",
    "print(\"\\nRunning optimization ...\")\n",
    "results_evobandits = []\n",
    "\n",
    "for run_id in tqdm(range(N_RUNS), desc=\"EvoBandits | Run\"):\n",
    "    seed = SEED + run_id\n",
    "    gmab = GMAB(population_size=10)\n",
    "    study = Study(seed=seed, algorithm=gmab)\n",
    "    study.optimize(objective, params, n_trials=SIM_BUDGET)\n",
    "    print(f\"Config:\\t{study.best_params}\")\n",
    "    print(f\"Value:\\t{study.best_value}\")\n",
    "\n",
    "    mean_evaluation, evaluations = estimate_true_value(seed, study.best_params)\n",
    "    print(f\"Est. true value:\\t{mean_evaluation}\")\n",
    "\n",
    "    results_evobandits.append({\n",
    "        \"mean_evaluation\": mean_evaluation,\n",
    "        \"evaluations\": evaluations,\n",
    "        \"best_solution\": study.best_solution,\n",
    "        \"seed\": seed\n",
    "    })\n",
    "\n",
    "    with open(Path(\"_data/04_results_evobandits.json\"), 'w') as f:\n",
    "        json.dump(results_evobandits, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4bc81",
   "metadata": {},
   "source": [
    "### 2.2 Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3469873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(budget, seed):\n",
    "    # Evaluate the GA with random configurations\n",
    "    random_search_results = {}\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(budget):\n",
    "        seed = rng.integers(0, 2**32 - 1, dtype=int)\n",
    "        rnd_config = randomize_configuration(seed)\n",
    "        cost, _ = genetic_algorithm(seed=seed, generations=GENERATIONS, **rnd_config)\n",
    "        random_search_results[cost] = rnd_config\n",
    "\n",
    "    # Find the config with the lowest cost\n",
    "    best_value = min(random_search_results.keys())\n",
    "    best_config = random_search_results[best_value]\n",
    "    return best_value, best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662488ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnd_search = []\n",
    "\n",
    "for run_id in tqdm(range(N_RUNS), desc=\"RandomSearch | Run\"):\n",
    "    print(\"\\nRunning optimization ...\")\n",
    "    seed = SEED + run_id\n",
    "    best_value, best_params = random_search(SIM_BUDGET, seed)\n",
    "    print(f\"Config:\\t{best_params}\")\n",
    "    print(f\"Value:\\t{best_value}\")\n",
    "\n",
    "    mean_evaluation, evaluations = estimate_true_value(seed, best_params)\n",
    "    print(f\"Est. true value:\\t{mean_evaluation}\")\n",
    "\n",
    "    results_rnd_search.append({\n",
    "        \"mean_evaluation\": mean_evaluation,\n",
    "        \"evaluations\": evaluations,\n",
    "        \"best_value\": best_value,\n",
    "        \"best_params\": best_params,\n",
    "        \"seed\": seed,\n",
    "    })\n",
    "\n",
    "    with open(Path(\"_data/04_results_rnd_search.json\"), 'w') as f:\n",
    "        json.dump(results_rnd_search, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0339d",
   "metadata": {},
   "source": [
    "### 2.3 IRACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga_runner(experiment: Experiment, scenario: Scenario):\n",
    "    \"\"\"Seeded, single-objective function to simulate the GA with irace.\"\"\"\n",
    "    best_cost, _ = genetic_algorithm(\n",
    "        generations=GENERATIONS, seed=experiment.seed, **experiment.configuration\n",
    "    )\n",
    "    return float(best_cost)\n",
    "\n",
    "param_space = ParameterSpace(\n",
    "    [\n",
    "        Ordinal(\"pop_size\", POP_SIZE_RANGE),\n",
    "        Ordinal(\"elite_split\", ELITE_SPLIT_RANGE),\n",
    "        Ordinal(\"tournament_split\", TOURNAMENT_SPLIT_RANGE),\n",
    "        Ordinal(\"crossover_rate\", CROSSOVER_RATE_RANGE),\n",
    "        Ordinal(\"mutation_rate\", MUTATION_RATE_RANGE),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nRunning optimization ...\")\n",
    "results_irace = []\n",
    "\n",
    "for run_id in tqdm(range(N_RUNS), desc=\"IRACE | Run\"):\n",
    "    print(\"\\nRunning optimization ...\")\n",
    "    seed = SEED + run_id\n",
    "    scenario = Scenario(\n",
    "        max_experiments=SIM_BUDGET,\n",
    "        verbose=0,\n",
    "    )\n",
    "    best_params = irace(ga_runner, param_space, scenario)[0]\n",
    "    print(f\"Config:\\t{best_params}\")\n",
    "\n",
    "    mean_evaluation, evaluations = estimate_true_value(seed, best_params)\n",
    "    print(f\"Est. true value:\\t{mean_evaluation}\")\n",
    "\n",
    "    results_irace.append({\n",
    "        \"mean_evaluation\": mean_evaluation,\n",
    "        \"evaluations\": evaluations,\n",
    "        \"best_params\": best_params,\n",
    "        \"seed\": seed,\n",
    "    })\n",
    "\n",
    "    with open(Path(\"_data/04_results_irace.json\"), 'w') as f:\n",
    "        json.dump(results_irace, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa14a7",
   "metadata": {},
   "source": [
    "## 3. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7358595",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "values_evobandits = [r[\"mean_evaluation\"] for r in results_evobandits]\n",
    "values_irace = [r[\"mean_evaluation\"] for r in results_irace]\n",
    "values_rand_search = [r[\"mean_evaluation\"] for r in results_rnd_search]\n",
    "\n",
    "plt.boxplot(\n",
    "    [values_evobandits, values_irace, values_rand_search], \n",
    "    tick_labels=[\"evobandits\", \"irace\", \"random search\"], \n",
    "    showmeans=True, meanprops={\"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, medianprops={\"color\": \"C0\"})\n",
    "plt.axhline(TSP_OPT_COST, linestyle='--', linewidth=1, color=\"C3\", label=\"Optimal Cost\")\n",
    "\n",
    "plt.ylabel(\"Total Distance\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"_plots/02_evobandits_demo_results.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f88a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "values_evobandits = [r[\"mean_evaluation\"] for r in results_evobandits]\n",
    "values_irace = [r[\"mean_evaluation\"] for r in results_irace]\n",
    "values_rand_search = [r[\"mean_evaluation\"] for r in results_rnd_search]\n",
    "plt.violinplot(\n",
    "    [values_evobandits, values_irace, values_rand_search], \n",
    "    showmeans=True)\n",
    "plt.axhline(TSP_OPT_COST, linestyle='--', linewidth=1, color=\"C3\", label=\"Optimal Cost\")\n",
    "\n",
    "plt.ylabel(\"Total Distance\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"_plots/06_comparison_by_optimizer.pdf\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
